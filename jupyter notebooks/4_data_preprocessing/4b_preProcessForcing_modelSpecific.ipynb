{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Specific Input Data Preprocessing in CONFLUENCE\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook covers the model-specific preprocessing steps for input data in CONFLUENCE. After completing the model-agnostic preprocessing, we now focus on tailoring our data to the specific requirements of the chosen hydrological model (e.g., SUMMA, HYPE, or MESH).\n",
    "\n",
    "Key aspects covered in this notebook include:\n",
    "\n",
    "1. Formatting data according to the chosen model's input specifications\n",
    "2. Generating model-specific configuration files\n",
    "3. Preparing initial conditions and parameter files\n",
    "4. Creating forcing data in the required format and resolution\n",
    "\n",
    "In this notebook we ensure that our preprocessed data is compatible with the chosen hydrological model. By the end of this process, you will have a complete set of input files ready for model initialization and simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we import the libraries and functions we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import logging\n",
    "import yaml # type: ignore\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "#from utils.dataHandling_utils.specificPreProcessor_util import SummaPreProcessor_spatial, flashPreProcessor # type: ignore\n",
    "from utils.models_utils.summa_utils import SummaPreProcessor_spatial # type: ignore\n",
    "from utils.models_utils.mizuroute_utils import MizuRoutePreProcessor\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check configurations\n",
    "\n",
    "Now we should print our configuration settings and make sure that we have defined all the settings we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORCING_DATASET: ERA5\n",
      "EASYMORE_CLIENT: easymore cli\n",
      "FORCING_VARIABLES: longitude,latitude,time,LWRadAtm,SWRadAtm,pptrate,airpres,airtemp,spechum,windspd\n",
      "EXPERIMENT_TIME_START: 2008-01-01 00:00\n",
      "EXPERIMENT_TIME_END: 2022-12-31 23:00\n"
     ]
    }
   ],
   "source": [
    "config_path = Path('../../0_config_files/config_active.yaml')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "    print(f\"FORCING_DATASET: {config['FORCING_DATASET']}\")\n",
    "    print(f\"EASYMORE_CLIENT: {config['EASYMORE_CLIENT']}\")\n",
    "    print(f\"FORCING_VARIABLES: {config['FORCING_VARIABLES']}\")\n",
    "    print(f\"EXPERIMENT_TIME_START: {config['EXPERIMENT_TIME_START']}\")\n",
    "    print(f\"EXPERIMENT_TIME_END: {config['EXPERIMENT_TIME_END']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define default paths\n",
    "\n",
    "Now let's define the paths to data directories before we run the pre processing scripts and create the containing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main project directory\n",
    "data_dir = config['CONFLUENCE_DATA_DIR']\n",
    "project_dir = Path(data_dir) / f\"domain_{config['DOMAIN_NAME']}\"\n",
    "\n",
    "# Data directoris\n",
    "model_input_dir = project_dir / f\"{config['HYDROLOGICAL_MODEL']}_input\"\n",
    "\n",
    "# Make sure the new directories exists\n",
    "model_input_dir.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 09:23:23,937 - INFO - Starting SUMMA spatial preprocessing\n",
      "2025-03-28 09:23:23,938 - INFO - Starting forcing data processing\n",
      "2025-03-28 09:23:23,939 - INFO - Starting to apply temperature lapse rate and add data step\n",
      "2025-03-28 09:23:23,938 - INFO - Starting forcing data processing\n",
      "2025-03-28 09:23:23,939 - INFO - Starting to apply temperature lapse rate and add data step\n",
      "2025-03-28 09:23:23,948 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200801.nc\n",
      "2025-03-28 09:23:24,222 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200802.nc\n",
      "2025-03-28 09:23:24,315 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200803.nc\n",
      "2025-03-28 09:23:24,412 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200804.nc\n",
      "2025-03-28 09:23:24,522 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200805.nc\n",
      "2025-03-28 09:23:24,612 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200806.nc\n",
      "2025-03-28 09:23:24,697 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200807.nc\n",
      "2025-03-28 09:23:24,789 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200808.nc\n",
      "2025-03-28 09:23:24,876 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200809.nc\n",
      "2025-03-28 09:23:24,963 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200810.nc\n",
      "2025-03-28 09:23:25,051 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200811.nc\n",
      "2025-03-28 09:23:25,131 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200812.nc\n",
      "2025-03-28 09:23:25,214 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200901.nc\n",
      "2025-03-28 09:23:25,301 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200902.nc\n",
      "2025-03-28 09:23:25,379 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200903.nc\n",
      "2025-03-28 09:23:25,463 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200904.nc\n",
      "2025-03-28 09:23:25,543 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200905.nc\n",
      "2025-03-28 09:23:25,628 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200906.nc\n",
      "2025-03-28 09:23:25,710 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200907.nc\n",
      "2025-03-28 09:23:25,793 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200908.nc\n",
      "2025-03-28 09:23:25,873 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200909.nc\n",
      "2025-03-28 09:23:25,953 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200910.nc\n",
      "2025-03-28 09:23:26,035 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200911.nc\n",
      "2025-03-28 09:23:26,117 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_200912.nc\n",
      "2025-03-28 09:23:26,196 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201001.nc\n",
      "2025-03-28 09:23:26,277 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201002.nc\n",
      "2025-03-28 09:23:26,352 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201003.nc\n",
      "2025-03-28 09:23:26,436 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201004.nc\n",
      "2025-03-28 09:23:26,514 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201005.nc\n",
      "2025-03-28 09:23:26,597 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201006.nc\n",
      "2025-03-28 09:23:26,677 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201007.nc\n",
      "2025-03-28 09:23:26,757 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201008.nc\n",
      "2025-03-28 09:23:26,840 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201009.nc\n",
      "2025-03-28 09:23:26,920 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201010.nc\n",
      "2025-03-28 09:23:27,002 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201011.nc\n",
      "2025-03-28 09:23:27,081 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201012.nc\n",
      "2025-03-28 09:23:27,162 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201101.nc\n",
      "2025-03-28 09:23:27,244 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201102.nc\n",
      "2025-03-28 09:23:27,318 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201103.nc\n",
      "2025-03-28 09:23:27,399 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201104.nc\n",
      "2025-03-28 09:23:27,477 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201105.nc\n",
      "2025-03-28 09:23:27,558 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201106.nc\n",
      "2025-03-28 09:23:27,635 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201107.nc\n",
      "2025-03-28 09:23:27,719 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201108.nc\n",
      "2025-03-28 09:23:27,801 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201109.nc\n",
      "2025-03-28 09:23:27,880 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201110.nc\n",
      "2025-03-28 09:23:27,963 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201111.nc\n",
      "2025-03-28 09:23:28,042 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201112.nc\n",
      "2025-03-28 09:23:28,125 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201201.nc\n",
      "2025-03-28 09:23:28,209 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201202.nc\n",
      "2025-03-28 09:23:28,287 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201203.nc\n",
      "2025-03-28 09:23:28,368 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201204.nc\n",
      "2025-03-28 09:23:28,448 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201205.nc\n",
      "2025-03-28 09:23:28,531 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201206.nc\n",
      "2025-03-28 09:23:28,612 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201207.nc\n",
      "2025-03-28 09:23:28,694 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201208.nc\n",
      "2025-03-28 09:23:28,775 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201209.nc\n",
      "2025-03-28 09:23:28,856 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201210.nc\n",
      "2025-03-28 09:23:28,940 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201211.nc\n",
      "2025-03-28 09:23:29,022 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201212.nc\n",
      "2025-03-28 09:23:29,103 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201301.nc\n",
      "2025-03-28 09:23:29,184 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201302.nc\n",
      "2025-03-28 09:23:29,260 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201303.nc\n",
      "2025-03-28 09:23:29,343 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201304.nc\n",
      "2025-03-28 09:23:29,422 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201305.nc\n",
      "2025-03-28 09:23:29,505 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201306.nc\n",
      "2025-03-28 09:23:29,583 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201307.nc\n",
      "2025-03-28 09:23:29,665 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201308.nc\n",
      "2025-03-28 09:23:29,748 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201309.nc\n",
      "2025-03-28 09:23:29,828 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201310.nc\n",
      "2025-03-28 09:23:29,912 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201311.nc\n",
      "2025-03-28 09:23:29,993 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201312.nc\n",
      "2025-03-28 09:23:30,073 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201401.nc\n",
      "2025-03-28 09:23:30,155 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201402.nc\n",
      "2025-03-28 09:23:30,229 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201403.nc\n",
      "2025-03-28 09:23:30,310 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201404.nc\n",
      "2025-03-28 09:23:30,392 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201405.nc\n",
      "2025-03-28 09:23:30,473 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201406.nc\n",
      "2025-03-28 09:23:30,553 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201407.nc\n",
      "2025-03-28 09:23:30,660 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201408.nc\n",
      "2025-03-28 09:23:30,741 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201409.nc\n",
      "2025-03-28 09:23:30,821 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201410.nc\n",
      "2025-03-28 09:23:30,903 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201411.nc\n",
      "2025-03-28 09:23:30,985 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201412.nc\n",
      "2025-03-28 09:23:31,065 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201501.nc\n",
      "2025-03-28 09:23:31,150 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201502.nc\n",
      "2025-03-28 09:23:31,225 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201503.nc\n",
      "2025-03-28 09:23:31,306 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201504.nc\n",
      "2025-03-28 09:23:31,385 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201505.nc\n",
      "2025-03-28 09:23:31,468 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201506.nc\n",
      "2025-03-28 09:23:31,546 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201507.nc\n",
      "2025-03-28 09:23:31,629 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201508.nc\n",
      "2025-03-28 09:23:31,710 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201509.nc\n",
      "2025-03-28 09:23:31,789 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201510.nc\n",
      "2025-03-28 09:23:31,873 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201511.nc\n",
      "2025-03-28 09:23:31,953 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201512.nc\n",
      "2025-03-28 09:23:32,033 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201601.nc\n",
      "2025-03-28 09:23:32,114 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201602.nc\n",
      "2025-03-28 09:23:32,192 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201603.nc\n",
      "2025-03-28 09:23:32,277 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201604.nc\n",
      "2025-03-28 09:23:32,356 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201605.nc\n",
      "2025-03-28 09:23:32,438 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201606.nc\n",
      "2025-03-28 09:23:32,520 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201607.nc\n",
      "2025-03-28 09:23:32,603 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201608.nc\n",
      "2025-03-28 09:23:32,687 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201609.nc\n",
      "2025-03-28 09:23:32,765 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201610.nc\n",
      "2025-03-28 09:23:32,848 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201611.nc\n",
      "2025-03-28 09:23:32,928 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201612.nc\n",
      "2025-03-28 09:23:33,009 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201701.nc\n",
      "2025-03-28 09:23:33,093 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201702.nc\n",
      "2025-03-28 09:23:33,168 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201703.nc\n",
      "2025-03-28 09:23:33,247 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201704.nc\n",
      "2025-03-28 09:23:33,327 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201705.nc\n",
      "2025-03-28 09:23:33,409 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201706.nc\n",
      "2025-03-28 09:23:33,489 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201707.nc\n",
      "2025-03-28 09:23:33,571 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201708.nc\n",
      "2025-03-28 09:23:33,653 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201709.nc\n",
      "2025-03-28 09:23:33,734 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201710.nc\n",
      "2025-03-28 09:23:33,816 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201711.nc\n",
      "2025-03-28 09:23:33,898 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201712.nc\n",
      "2025-03-28 09:23:33,982 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201801.nc\n",
      "2025-03-28 09:23:34,063 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201802.nc\n",
      "2025-03-28 09:23:34,139 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201803.nc\n",
      "2025-03-28 09:23:34,222 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201804.nc\n",
      "2025-03-28 09:23:34,302 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201805.nc\n",
      "2025-03-28 09:23:34,385 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201806.nc\n",
      "2025-03-28 09:23:34,465 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201807.nc\n",
      "2025-03-28 09:23:34,550 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201808.nc\n",
      "2025-03-28 09:23:34,631 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201809.nc\n",
      "2025-03-28 09:23:34,711 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201810.nc\n",
      "2025-03-28 09:23:34,794 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201811.nc\n",
      "2025-03-28 09:23:34,875 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201812.nc\n",
      "2025-03-28 09:23:34,958 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201901.nc\n",
      "2025-03-28 09:23:35,040 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201902.nc\n",
      "2025-03-28 09:23:35,115 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201903.nc\n",
      "2025-03-28 09:23:35,195 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201904.nc\n",
      "2025-03-28 09:23:35,280 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201905.nc\n",
      "2025-03-28 09:23:35,361 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201906.nc\n",
      "2025-03-28 09:23:35,444 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201907.nc\n",
      "2025-03-28 09:23:35,524 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201908.nc\n",
      "2025-03-28 09:23:35,608 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201909.nc\n",
      "2025-03-28 09:23:35,689 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201910.nc\n",
      "2025-03-28 09:23:35,772 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201911.nc\n",
      "2025-03-28 09:23:35,852 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_201912.nc\n",
      "2025-03-28 09:23:35,936 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202001.nc\n",
      "2025-03-28 09:23:36,017 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202002.nc\n",
      "2025-03-28 09:23:36,096 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202003.nc\n",
      "2025-03-28 09:23:36,179 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202004.nc\n",
      "2025-03-28 09:23:36,260 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202005.nc\n",
      "2025-03-28 09:23:36,342 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202006.nc\n",
      "2025-03-28 09:23:36,420 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202007.nc\n",
      "2025-03-28 09:23:36,504 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202008.nc\n",
      "2025-03-28 09:23:36,589 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202009.nc\n",
      "2025-03-28 09:23:36,669 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202010.nc\n",
      "2025-03-28 09:23:36,749 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202011.nc\n",
      "2025-03-28 09:23:36,831 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202012.nc\n",
      "2025-03-28 09:23:36,914 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202101.nc\n",
      "2025-03-28 09:23:36,999 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202102.nc\n",
      "2025-03-28 09:23:37,076 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202103.nc\n",
      "2025-03-28 09:23:37,159 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202104.nc\n",
      "2025-03-28 09:23:37,242 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202105.nc\n",
      "2025-03-28 09:23:37,325 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202106.nc\n",
      "2025-03-28 09:23:37,405 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202107.nc\n",
      "2025-03-28 09:23:37,487 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202108.nc\n",
      "2025-03-28 09:23:37,568 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202109.nc\n",
      "2025-03-28 09:23:37,648 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202110.nc\n",
      "2025-03-28 09:23:37,731 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202111.nc\n",
      "2025-03-28 09:23:37,810 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202112.nc\n",
      "2025-03-28 09:23:37,893 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202201.nc\n",
      "2025-03-28 09:23:37,976 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202202.nc\n",
      "2025-03-28 09:23:38,053 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202203.nc\n",
      "2025-03-28 09:23:38,137 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202204.nc\n",
      "2025-03-28 09:23:38,218 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202205.nc\n",
      "2025-03-28 09:23:38,301 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202206.nc\n",
      "2025-03-28 09:23:38,381 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202207.nc\n",
      "2025-03-28 09:23:38,465 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202208.nc\n",
      "2025-03-28 09:23:38,548 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202209.nc\n",
      "2025-03-28 09:23:38,627 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202210.nc\n",
      "2025-03-28 09:23:38,711 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202211.nc\n",
      "2025-03-28 09:23:38,821 - INFO - Processing Wolverine_ERA5_remapped_domain_Wolverine_ERA5_merged_202212.nc\n",
      "2025-03-28 09:23:38,904 - INFO - Completed processing of ERA5 forcing files with temperature lapsing\n",
      "2025-03-28 09:23:38,905 - INFO - Datasetp and Lapse rate correction applied successfully\n",
      "2025-03-28 09:23:38,906 - INFO - Forcing data processing completed successfully\n",
      "2025-03-28 09:23:38,906 - INFO - Copying SUMMA base settings\n",
      "2025-03-28 09:23:38,911 - INFO - SUMMA base settings copied to /Users/amedin/Research/Confluence/CONFLUENCE_data/domain_Wolverine/settings/SUMMA\n",
      "2025-03-28 09:23:38,911 - INFO - Creating SUMMA file manager\n",
      "2025-03-28 09:23:38,913 - INFO - SUMMA file manager created at /Users/amedin/Research/Confluence/CONFLUENCE_data/domain_Wolverine/settings/SUMMA/fileManager.txt\n",
      "2025-03-28 09:23:38,913 - INFO - Creating forcing file list\n",
      "2025-03-28 09:23:38,914 - INFO - Forcing file list created at /Users/amedin/Research/Confluence/CONFLUENCE_data/domain_Wolverine/settings/SUMMA/forcingFileList.txt\n",
      "2025-03-28 09:23:38,914 - INFO - Creating initial conditions (cold state) file\n",
      "2025-03-28 09:23:38,914 - INFO - Creating initial conditions (cold state) file\n",
      "2025-03-28 09:23:38,930 - INFO - Initial conditions file created at: /Users/amedin/Research/Confluence/CONFLUENCE_data/domain_Wolverine/settings/SUMMA/coldState.nc\n",
      "2025-03-28 09:23:38,931 - INFO - Creating trial parameters file\n",
      "2025-03-28 09:23:38,939 - INFO - Trial parameters file created at: /Users/amedin/Research/Confluence/CONFLUENCE_data/domain_Wolverine/settings/SUMMA/trialParams.nc\n",
      "2025-03-28 09:23:38,940 - INFO - Creating attributes file\n",
      "2025-03-28 09:23:38,943 - INFO - Calculating slope and contour length for each HRU\n",
      "/Users/amedin/Research/Confluence/CONFLUENCE/utils/models_utils/summa_utils.py:1553: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  contour_lengths = np.sqrt(shp.geometry.area)\n",
      "2025-03-28 09:23:39,057 - INFO - Attributes file created at: /Users/amedin/Research/Confluence/CONFLUENCE_data/domain_Wolverine/settings/SUMMA/attributes.nc\n",
      "2025-03-28 09:23:39,058 - INFO - Inserting soil class into attributes file\n",
      "2025-03-28 09:23:39,064 - INFO - Replacing soil class -999 with 8 at HRU 1\n",
      "2025-03-28 09:23:39,065 - INFO - Replacing soil class -999 with 8 at HRU 2\n",
      "2025-03-28 09:23:39,067 - INFO - Replacing soil class -999 with 8 at HRU 3\n",
      "2025-03-28 09:23:39,067 - INFO - Inserting land class into attributes file\n",
      "2025-03-28 09:23:39,073 - INFO - Replacing land class -999 with 10 at HRU 1\n",
      "2025-03-28 09:23:39,075 - INFO - Replacing land class -999 with 15 at HRU 2\n",
      "2025-03-28 09:23:39,076 - INFO - Replacing land class -999 with 15 at HRU 3\n",
      "2025-03-28 09:23:39,077 - INFO - 0 HRUs were identified as containing only open water. Note that SUMMA skips hydrologic calculations for such HRUs.\n",
      "2025-03-28 09:23:39,078 - INFO - Inserting elevation into attributes file\n",
      "2025-03-28 09:23:39,084 - INFO - Set elevation for HRU 1 to 735.3214786264891\n",
      "2025-03-28 09:23:39,086 - INFO - Set elevation for HRU 2 to 1115.2288281634662\n",
      "2025-03-28 09:23:39,087 - INFO - Set elevation for HRU 3 to 1409.8245578778135\n",
      "2025-03-28 09:23:39,088 - INFO - SUMMA spatial preprocessing completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize model specific preprocessors\n",
    "\n",
    "if config['HYDROLOGICAL_MODEL'] == 'SUMMA':\n",
    "    ssp = SummaPreProcessor_spatial(config, logger)\n",
    "    ssp.run_preprocessing()\n",
    "\n",
    "    if config['DOMAIN_DEFINITION_METHOD'] != 'lumped': # lumped domain definition has no routing\n",
    "        mp = MizuRoutePreProcessor(config,logger)\n",
    "        mp.run_preprocessing()\n",
    "    \n",
    "    \n",
    "elif config['HYDROLOGICAL_MODEL'] == 'FLASH':\n",
    "    ssp = flashPreProcessor(config, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Glacier attibutes and initial conditions (cold state) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic functions\n",
    "import numpy as np\n",
    "import netCDF4 as nc4\n",
    "import shutil\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.transform import xy\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from pyproj import CRS\n",
    "\n",
    "def getNetCDFData(fn, varname):\n",
    "    \"\"\"Read <varname> variables available to be mapped from NetCDF <fn> \"\"\"\n",
    "    f = nc4.Dataset(fn,'r')\n",
    "    data = f.variables[varname][:]\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def getOutputPolyIDs(nc_file):\n",
    "    outPolyIDs  = getNetCDFData(nc_file, 'hruId')    \n",
    "    hru_elev = getNetCDFData(nc_file, 'elevation')\n",
    "    hru_area = getNetCDFData(nc_file, 'HRUarea')\n",
    "    gruIDs = getNetCDFData(nc_file, 'gruId')\n",
    "    hru2gru = getNetCDFData(nc_file, 'hru2gruId')\n",
    "    print(\"read data from attribute file\")\n",
    "    return outPolyIDs,hru_elev,hru_area, gruIDs,hru2gru\n",
    "\n",
    "# write gru, variables to netcdf output file\n",
    "def writeNC_state_vars_GRU(nc_out, newVarName, newVarType, newVarVals):\n",
    "    \"\"\" Write <vars>[gru] array in netCDF4 file,<fn> and variable of\n",
    "        <varname> \"\"\"\n",
    "    print(\"adding attribute data\")\n",
    "    ncvar = nc_out.createVariable(newVarName, newVarType, ('gru',),fill_value='-999')    \n",
    "    ncvar[:] = newVarVals   # store data in netcdf file\n",
    "\n",
    "# write gru nonscalar variables to netcdf output file\n",
    "def writeNC_state_vars_GRU_VEC(nc_out, newVarName, newVarDim, newVarType, newVarVals):\n",
    "    \"\"\" Write <vars>[gru] array in netCDF4 file,<fn> and variable of\n",
    "        <varname> \"\"\"\n",
    "    print(\"adding GRU_VEC data\")\n",
    "    if newVarType=='i4' or newVarType=='i8':\n",
    "        ncvar = nc_out.createVariable(newVarName, newVarType, (newVarDim,'gru',),fill_value='-999')  \n",
    "    else:\n",
    "        ncvar = nc_out.createVariable(newVarName, newVarType, (newVarDim,'gru',),fill_value='-999.0')  \n",
    "    ncvar[:] = newVarVals   # store data in netcdf file\n",
    "\n",
    "# write gru grid variables to netcdf output file\n",
    "def writeNC_state_vars_GRU_GRID(nc_out, newVarName, newVarDim1,newVarDim2, newVarType, newVarVals):\n",
    "    \"\"\" Write <vars>[gru] array in netCDF4 file,<fn> and variable of\n",
    "        <varname> \"\"\"\n",
    "    print(\"adding GRU_GRID data\")\n",
    "    if newVarType=='i4' or newVarType=='i8':\n",
    "        ncvar = nc_out.createVariable(newVarName, newVarType, (newVarDim1,newVarDim2,'grid','gru',),fill_value='-999')    \n",
    "    else:\n",
    "        ncvar = nc_out.createVariable(newVarName, newVarType, (newVarDim1,newVarDim2,'grid','gru',),fill_value='-999.0')    \n",
    "    ncvar[:,:] = newVarVals   # store data in netcdf file\n",
    "\n",
    "# write dom, hru, variables to netcdf output file\n",
    "def writeNC_state_vars_HRU_DOM(nc_out, newVarName, newVarDim, newVarType, newVarVals):\n",
    "    \"\"\" Write <vars>[hru dom] array in netCDF4 file,<fn> and variable of\n",
    "        <varname> \"\"\"\n",
    "    print(\"adding HRU_DOM data\")\n",
    "    ncvar = nc_out.createVariable(newVarName, newVarType, (newVarDim,'hru','dom',),fill_value='-999.0')   \n",
    "    ncvar[:] = newVarVals   # store data in netcdf file\n",
    "\n",
    "# write dimensions and dimension variables to netcdf output file\n",
    "def writeNC_dimsGRU(fn, grus, hru_type, glac, nx, ny):    \n",
    "    \"\"\" Write <vars> array in netCDF4 file,<fn> and variable of\n",
    "        <varname> \"\"\"\n",
    "    print(\"writing output file\")\n",
    "    nc_out = nc4.Dataset(fn, mode='w', format='NETCDF4')\n",
    "    # Create dimensions\n",
    "    dim_gru = nc_out.createDimension('gru', len(grus))\n",
    "    dim_ngl = nc_out.createDimension('grid', glac) # max number of glaciers in any GRU\n",
    "    dim_nx = nc_out.createDimension('xgrid', nx) # max number of cells in glacier bed\n",
    "    dim_ny = nc_out.createDimension('ygrid', ny) # max number of cells in glacier bed\n",
    "    # --- Create HRU ID variable (can be either int or string)\n",
    "    if hru_type == 'str':\n",
    "        # string HRU (need to add string length)\n",
    "        max_strlen = 20  # EC\n",
    "        dim_str = nc_out.createDimension('strlen', max_strlen)\n",
    "        gruId = nc_out.createVariable('gruId', 'S1', ('gru', 'strlen'),fill_value='-999')\n",
    "        gruId[:] = nc4.stringtochar(np.asarray(np.unique(grus),\n",
    "                                  dtype='S{}'.format(max_strlen)))\n",
    "    elif hru_type == 'int64':\n",
    "        # integer HRU\n",
    "        gruId = nc_out.createVariable('gruId', 'i8', ('gru', ),fill_value='-999')\n",
    "        gruId[:] = grus\n",
    "    elif hru_type == 'int':\n",
    "        # integer HRU\n",
    "        gruId = nc_out.createVariable('gruId', 'int', ('gru', ),fill_value='-999')\n",
    "        gruId[:] = grus\n",
    "    else:\n",
    "        # not recognized\n",
    "        sys.exit(\"ERROR, hru_type not recognized: must be str, int64, or int\")\n",
    "    # add attribute    \n",
    "    gruId.long_name = 'GRU ID'\n",
    "    return nc_out # leave netcdf file open\n",
    "\n",
    "    # write dimensions and dimension variables to netcdf output file\n",
    "def writeNC_dims(fn,  scalarv, midSoil, midToto, ifcToto, hrus, grus, hru_type, ndom, glac):    \n",
    "    \"\"\" Write <vars>[hru] array in netCDF4 file,<fn> and variable of\n",
    "        <varname> \"\"\"\n",
    "    print(\"writing output file\")\n",
    "    nc_out = nc4.Dataset(fn, 'w', format='NETCDF4')\n",
    "    # Create dimensions\n",
    "    dim_hru = nc_out.createDimension('hru', len(hrus))\n",
    "    dim_gru = nc_out.createDimension('gru', len(grus))\n",
    "    dim_scalarv = nc_out.createDimension('scalarv', scalarv)\n",
    "    dim_midSoil = nc_out.createDimension('midSoil', midSoil)\n",
    "    dim_midToto = nc_out.createDimension('midToto', midToto)\n",
    "    dim_ifcToto = nc_out.createDimension('ifcToto', ifcToto)    \n",
    "    dim_ndom = nc_out.createDimension('dom', ndom) # max number of domains in any HRU\n",
    "    dim_ngl = nc_out.createDimension('glac', glac) # max number of glaciers in any GRU\n",
    "    # --- Create HRU ID variable (can be either int or string)\n",
    "    if hru_type == 'str':\n",
    "        # string HRU (need to add string length)\n",
    "        max_strlen = 20  # EC\n",
    "        dim_str = nc_out.createDimension('strlen', max_strlen)\n",
    "        hruId = nc_out.createVariable('hruId', 'S1', ('hru', 'strlen'),fill_value='-999')  \n",
    "        hruId[:] = nc4.stringtochar(np.asarray(hrus,\n",
    "                                  dtype='S{}'.format(max_strlen)))     \n",
    "        gruId = nc_out.createVariable('gruId', 'S1', ('gru', 'strlen'),fill_value='-999')\n",
    "        gruId[:] = nc4.stringtochar(np.asarray(np.unique(grus),\n",
    "                                  dtype='S{}'.format(max_strlen)))\n",
    "    elif hru_type == 'int64':\n",
    "        # integer HRU\n",
    "        hruId = nc_out.createVariable('hruId', 'i8', ('hru', ),fill_value='-999')   \n",
    "        hruId[:] = hrus\n",
    "        #hruId[:] = np.asarray(hrus, dtype='int')\n",
    "        gruId = nc_out.createVariable('gruId', 'i8', ('gru', ),fill_value='-999')\n",
    "        gruId[:] = grus\n",
    "    elif hru_type == 'int':\n",
    "        # integer HRU\n",
    "        hruId = nc_out.createVariable('hruId', 'int', ('hru', ),fill_value='-999')   \n",
    "        hruId[:] = hrus\n",
    "        #hruId[:] = np.asarray(hrus, dtype='int')\n",
    "        gruId = nc_out.createVariable('gruId', 'int', ('gru', ),fill_value='-999')\n",
    "        gruId[:] = grus\n",
    "    else:\n",
    "        # not recognized\n",
    "        sys.exit(\"ERROR, hru_type not recognized: must be str, int64, or int\")\n",
    "    # add attribute    \n",
    "    hruId.long_name = 'USGS HUC12 ID'\n",
    "    gruId.long_name = 'GRU ID'\n",
    "    return nc_out # leave netcdf file open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for making the rasters in meters\n",
    "# NOTE: this could be bad since we are reprojecting a reprojected raster\n",
    "#       but we needed to do the first reproject to get the correct bounding box\n",
    "def reproject_to_utm(src_path, dst_path, utm_epsg):\n",
    "    with rasterio.open(src_path) as src:\n",
    "        # Get the CRS of the source raster\n",
    "        src_crs = src.crs\n",
    "        \n",
    "        # Determine the UTM zone based on the provided EPSG code\n",
    "        utm_crs = CRS.from_epsg(utm_epsg)\n",
    "        \n",
    "        # Calculate the transform and dimensions for the destination raster\n",
    "        transform, width, height = calculate_default_transform(src_crs, utm_crs, src.width, src.height, *src.bounds)\n",
    "        \n",
    "        # Update the metadata for the destination raster\n",
    "        dst_meta = src.meta.copy()\n",
    "        dst_meta.update({\n",
    "            'crs': utm_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "        \n",
    "        # Reproject and save the raster\n",
    "        with rasterio.open(dst_path, 'w', **dst_meta) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src_crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=utm_crs,\n",
    "                    resampling=Resampling.nearest\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data from attribute file\n"
     ]
    }
   ],
   "source": [
    "# Set up paths for grids\n",
    "data_dir = config['CONFLUENCE_DATA_DIR']\n",
    "domain_name = config['DOMAIN_NAME']\n",
    "project_dir = Path(data_dir) / f\"domain_{config['DOMAIN_NAME']}\"\n",
    "attribute_name = config['SETTINGS_SUMMA_ATTRIBUTES']\n",
    "coldstate_name = config['SETTINGS_SUMMA_COLDSTATE']\n",
    "attribute_path =  project_dir / 'settings/SUMMA'/ attribute_name\n",
    "coldstate_path =  project_dir / 'settings/SUMMA'/ coldstate_name\n",
    "glacier_dir = project_dir / 'attributes' / 'glaciers'\n",
    "\n",
    "# attributes are hardwired to forcing formats (hru index rather than grid)\n",
    "outPolyIDs, hru_elev, hru_area, gruIDs, hru2gru = getOutputPolyIDs(attribute_path)        \n",
    "nOutPolygonsHRU = len(outPolyIDs)\n",
    "nOutPolygonsGRU = len(gruIDs)\n",
    "nc_outTopo_name = config['SETTINGS_SUMMA_ATTRIBUTES'][:-3] + '_glacBedTopo.nc'\n",
    "nc_outTopo_path = project_dir / 'settings/SUMMA'/ nc_outTopo_name\n",
    "nc_outSurf_name = config['SETTINGS_SUMMA_COLDSTATE'][:-3] + '_glacSurfTopo.nc'\n",
    "nc_outSurf_path = project_dir / 'settings/SUMMA'/ nc_outSurf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths of rasters of glacier bed and surface topography\n",
    "bed_path = project_dir / 'attributes' / 'elevation' / 'dem' / f\"domain_{config['DOMAIN_NAME']}_bedrock_elv.tif\"\n",
    "surf_path = project_dir / 'attributes' / 'elevation' / 'dem' / f\"domain_{config['DOMAIN_NAME']}_elv.tif\"\n",
    "debris_path = glacier_dir / f\"domain_{config['DOMAIN_NAME']}_debris_thickness.tif\"\n",
    "hru_id_path = glacier_dir / f\"domain_{config['DOMAIN_NAME']}_hru_id.tif\"\n",
    "id_path = glacier_dir / f\"domain_{config['DOMAIN_NAME']}_glacier_id_extend.tif\" # only for glacier cells, not glacierets, extended\n",
    "type_path = glacier_dir / f\"domain_{config['DOMAIN_NAME']}_domain_type.tif\" # glacier or glacieret\n",
    "\n",
    "# paths of reprojected rasters\n",
    "temp_dir = glacier_dir / 'utm_temp'\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "bed_utm_path = temp_dir / \"bedrock_elv_utm.tif\"\n",
    "surf_utm_path = temp_dir / \"elv_utm.tif\"\n",
    "debris_utm_path = temp_dir / \"debris_thickness_utm.tif\"\n",
    "hru_id_utm_path = temp_dir / \"hru_id_utm.tif\"\n",
    "id_utm_path = temp_dir / \"glacier_id_utm.tif\"\n",
    "type_utm_path = temp_dir / \"domain_type_utm.tif\"\n",
    "\n",
    "# reproject to UTM\n",
    "utm_epsg = 32606 # UTM zone 6N for Alaska\n",
    "reproject_to_utm(bed_path, bed_utm_path, utm_epsg)\n",
    "reproject_to_utm(surf_path, surf_utm_path, utm_epsg)\n",
    "reproject_to_utm(debris_path, debris_utm_path, utm_epsg)\n",
    "reproject_to_utm(hru_id_path, hru_id_utm_path, utm_epsg)\n",
    "reproject_to_utm(id_path, id_utm_path, utm_epsg)\n",
    "reproject_to_utm(type_path, type_utm_path, utm_epsg)\n",
    "\n",
    "# read the reprojected rasters\n",
    "bed = rasterio.open(bed_utm_path)\n",
    "surf = rasterio.open(surf_utm_path)\n",
    "debris = rasterio.open(debris_utm_path)\n",
    "hru_id = rasterio.open(hru_id_utm_path)\n",
    "id = rasterio.open(id_utm_path)\n",
    "type = rasterio.open(type_utm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru: 1\n",
      "hrus: [1 2 3]\n",
      "glaciers considered in GRU 0: [np.int32(100332), np.int32(100333), np.int32(100334), np.int32(100570), np.int32(122903)]\n"
     ]
    }
   ],
   "source": [
    "# for each glacier id, if entire glacier has a value in hru_id, then build a grid\n",
    "nGlacier = np.zeros(nOutPolygonsGRU, dtype='i4')\n",
    "basin__GlacierStorage = np.zeros(nOutPolygonsGRU, dtype='f8') # used in initial condition\n",
    "max_glac = np.unique(id.read(1)).size\n",
    "gridId0 = np.zeros((1, max_glac, nOutPolygonsGRU), dtype='i8')\n",
    "threshold = 0.8 # threshold for glacier cells that must be in gru to be included (should be 1.0 but DEMs are not perfect)\n",
    "\n",
    "for i in range(nOutPolygonsGRU):\n",
    "    gru = gruIDs[i]\n",
    "    print(f\"gru: {gru}\")\n",
    "    hrus = outPolyIDs[hru2gru==gru]\n",
    "    print(f\"hrus: {hrus}\")\n",
    "    gru_cells = np.isin(hru_id.read(1),hrus)  \n",
    "    \n",
    "    # get glacier and glacieret volume in gru\n",
    "    gru_surf = surf.read(1)[gru_cells]\n",
    "    gru_bed = bed.read(1)[gru_cells]\n",
    "    basin__GlacierStorage[i] = bed.res[0]*bed.res[1]*np.sum((gru_surf-gru_bed))*916.7e-9 # in Gt\n",
    "\n",
    "    glac_id_cells = id.read(1)[gru_cells]  \n",
    "    some_glac_in_gru = np.unique(glac_id_cells)\n",
    "\n",
    "    # disclude id 0 and if glacier is not mostly in gru (by threshold)\n",
    "    some_glac_in_gru = some_glac_in_gru[some_glac_in_gru>0]\n",
    "    all_glac_in_gru = []\n",
    "    for gid in some_glac_in_gru:\n",
    "        if glac_id_cells[glac_id_cells==gid].size >= threshold*id.read(1)[id.read(1)==gid].size:\n",
    "            all_glac_in_gru.append(gid)\n",
    "    print(f\"glaciers considered in GRU {i}: {all_glac_in_gru}\")\n",
    "    nGlacier[i] = len(all_glac_in_gru)\n",
    "    gridId0[0,0:nGlacier[i],i] = all_glac_in_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make arrays\n",
    "glac = max(nGlacier)\n",
    "gridId = gridId0[:,0:glac,:]\n",
    "nx = np.zeros((1, glac, nOutPolygonsGRU), dtype='i4')\n",
    "ny = np.zeros((1, glac, nOutPolygonsGRU), dtype='i4')\n",
    "# dx, dy in meters since in UTM\n",
    "dx = np.full((1, glac, nOutPolygonsGRU), bed.res[0], dtype='f8')\n",
    "dy = np.full((1, glac, nOutPolygonsGRU), bed.res[1], dtype='f8')\n",
    "\n",
    "# make at max size initially, then resize later\n",
    "dim_nx = bed.read(1).shape[1]\n",
    "dim_ny = bed.read(1).shape[0]\n",
    "B0 = np.zeros((dim_ny, dim_nx, glac, nOutPolygonsGRU), dtype='f8')\n",
    "S0 = np.zeros((dim_ny, dim_nx, glac, nOutPolygonsGRU), dtype='f8')\n",
    "glacierMask0 = np.zeros((dim_ny, dim_nx, glac, nOutPolygonsGRU), dtype='i4')\n",
    "cell2hruId0  = np.zeros((dim_ny, dim_nx, glac, nOutPolygonsGRU), dtype='i8')\n",
    "type0 = np.zeros((dim_ny, dim_nx, glac, nOutPolygonsGRU), dtype='i4')\n",
    "debris_thick0 = np.zeros((dim_ny, dim_nx, glac, nOutPolygonsGRU), dtype='f8')\n",
    "glacAblArea = np.zeros((glac,nOutPolygonsGRU), dtype='f8') # used in initial condition\n",
    "glacAccArea = np.zeros((glac,nOutPolygonsGRU), dtype='f8') # used in initial condition\n",
    "lat_moraine_wid = np.zeros((glac,nOutPolygonsGRU), dtype='f8') # used in initial condition\n",
    "\n",
    "# get glacier cell data for each glacier\n",
    "for i in range(nOutPolygonsGRU):\n",
    "    for j in range(nGlacier[i]):\n",
    "        \n",
    "        # get glacier cells for this glacier\n",
    "        glac_cells = np.where(id.read(1) == gridId[0,j,i])\n",
    "        max_x = glac_cells[1].max()\n",
    "        min_x = glac_cells[1].min()\n",
    "        max_y = glac_cells[0].max()\n",
    "        min_y = glac_cells[0].min()\n",
    "        nx0 = max_x - min_x + 1 # right-left\n",
    "        ny0 = max_y - min_y + 1 # top-bottom\n",
    "        nx[0,j,i] = nx0\n",
    "        ny[0,j,i] = ny0\n",
    "        B0[:ny0,:nx0,j,i] = bed.read(1)[min_y:max_y+1,min_x:max_x+1]\n",
    "        S0[:ny0,:nx0,j,i] = surf.read(1)[min_y:max_y+1,min_x:max_x+1]\n",
    "        mask0 = np.zeros((dim_ny, dim_nx), dtype='i4')\n",
    "        mask0[glac_cells] = 1\n",
    "        glacierMask0[:ny0,:nx0,j,i] = mask0[min_y:max_y+1,min_x:max_x+1]\n",
    "        type0[:ny0,:nx0,j,i] = type.read(1)[min_y:max_y+1,min_x:max_x+1]\n",
    "\n",
    "        # equate B0 and S0 if cells are not in glacier\n",
    "        B0[:ny0,:nx0,j,i][glacierMask0[:ny0,:nx0,j,i]==0] = S0[:ny0,:nx0,j,i][glacierMask0[:ny0,:nx0,j,i]==0]\n",
    "        cell2hruId0[:ny0,:nx0,j,i] = hru_id.read(1)[min_y:max_y+1,min_x:max_x+1]\n",
    "\n",
    "        # set debris thickness to 0 if not in glacier\n",
    "        debris_thick0[:ny0,:nx0,j,i] = debris.read(1)[min_y:max_y+1,min_x:max_x+1]\n",
    "        debris_thick0[:ny0,:nx0,j,i][glacierMask0[:ny0,:nx0,j,i]==0] = 0\n",
    "        \n",
    "        # sum area of glacier cells in each glacier if type is 2 (accumulation) or 3,4 (ablation)\n",
    "        glacAccArea[j,i] = np.sum(bed.res[0]*bed.res[1]*glacierMask0[:ny0,:nx0,j,i][type0[:ny0,:nx0,j,i]==2])\n",
    "        glacAblArea[j,i] = bed.res[0]*bed.res[1]*(np.sum(glacierMask0[:ny0,:nx0,j,i][type0[:ny0,:nx0,j,i]==3]) +\n",
    "                                               np.sum(glacierMask0[:ny0,:nx0,j,i][type0[:ny0,:nx0,j,i]==4]))\n",
    "\n",
    "# resize arrays\n",
    "dim_nx = nx.max()\n",
    "dim_ny = ny.max()\n",
    "B = B0[:dim_ny,:dim_nx,:,:]\n",
    "S = S0[:dim_ny,:dim_nx,:,:]\n",
    "glacierMask = glacierMask0[:dim_ny,:dim_nx,:,:]\n",
    "cell2hruId = cell2hruId0[:dim_ny,:dim_nx,:,:]\n",
    "debris_thick = debris_thick0[:dim_ny,:dim_nx,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing output file\n",
      "writing output file\n",
      "adding attribute data\n",
      "adding GRU_VEC data\n",
      "adding GRU_VEC data\n",
      "adding GRU_VEC data\n",
      "adding GRU_VEC data\n",
      "adding GRU_VEC data\n",
      "adding GRU_GRID data\n",
      "adding GRU_GRID data\n",
      "adding GRU_GRID data\n",
      "adding GRU_VEC data\n",
      "adding GRU_GRID data\n",
      "adding GRU_GRID data\n"
     ]
    }
   ],
   "source": [
    "# create netcdf files and write dimensions\n",
    "nc_outTopo = writeNC_dimsGRU(nc_outTopo_path, gruIDs, 'int', glac, dim_nx, dim_ny)\n",
    "nc_outSurf = writeNC_dimsGRU(nc_outSurf_path, gruIDs, 'int', glac, dim_nx, dim_ny)\n",
    "\n",
    "# write variables to attributes file\n",
    "writeNC_state_vars_GRU(nc_outTopo, 'nGlacier', 'i4', nGlacier)\n",
    "writeNC_state_vars_GRU_VEC(nc_outTopo, 'gridId', 'grid', 'i8', gridId)\n",
    "writeNC_state_vars_GRU_VEC(nc_outTopo, 'nx', 'grid', 'i4', nx)\n",
    "writeNC_state_vars_GRU_VEC(nc_outTopo, 'ny', 'grid', 'i4', ny)\n",
    "writeNC_state_vars_GRU_VEC(nc_outTopo, 'dy', 'grid', 'f8', dy)\n",
    "writeNC_state_vars_GRU_VEC(nc_outTopo, 'dx', 'grid', 'f8', dx)\n",
    "writeNC_state_vars_GRU_GRID(nc_outTopo, 'bed_elev','ygrid','xgrid','f8', B)\n",
    "writeNC_state_vars_GRU_GRID(nc_outTopo, 'glacierMask','ygrid','xgrid','i4', glacierMask)\n",
    "writeNC_state_vars_GRU_GRID(nc_outTopo, 'cell2hruId','ygrid','xgrid','i8', cell2hruId)\n",
    "\n",
    "# write surface elevation and debris to initial conditions file\n",
    "writeNC_state_vars_GRU_VEC(nc_outSurf, 'gridId', 'grid', 'i8', gridId)\n",
    "writeNC_state_vars_GRU_GRID(nc_outSurf, 'surface_elev','ygrid','xgrid','f8', S)\n",
    "writeNC_state_vars_GRU_GRID(nc_outSurf, 'debris_thick','ygrid','xgrid','f8', debris_thick)\n",
    "\n",
    "# close files\n",
    "nc_outTopo.close()\n",
    "nc_outSurf.close()\n",
    "\n",
    "# remove temporary directory for reprojected UTM rasters\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up paths for HRU and domain spatial data\n",
    "nc_outAttr_name = config['SETTINGS_SUMMA_ATTRIBUTES'][:-3] + '_glac.nc'\n",
    "nc_outAttr_path = project_dir / 'settings/SUMMA'/ nc_outAttr_name\n",
    "nc_outInit_name = config['SETTINGS_SUMMA_COLDSTATE'][:-3] + '_glac.nc'\n",
    "nc_outInit_path = project_dir / 'settings/SUMMA'/ nc_outInit_name\n",
    "\n",
    "# for now, set nWetland to 0 (no wetlands)\n",
    "nWetland = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding attribute data\n",
      "adding attribute data\n"
     ]
    }
   ],
   "source": [
    "# make new attributes file\n",
    "shutil.copy(attribute_path, nc_outAttr_path)\n",
    "nc_outAttr = nc4.Dataset(nc_outAttr_path, 'a')\n",
    "writeNC_state_vars_GRU(nc_outAttr, 'nGlacier', 'i4', nGlacier)\n",
    "nWetland = np.full((nOutPolygonsGRU), nWetland, dtype='i4')\n",
    "writeNC_state_vars_GRU(nc_outAttr, 'nWetland', 'i4', nWetland)\n",
    "nc_outAttr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables at max size, then resize later\n",
    "realMissing = -9999.0\n",
    "ndom0 = 6 # number of possible domains\n",
    "DOMarea = np.zeros((1, nOutPolygonsHRU, ndom0), dtype='f8')\n",
    "DOMelev = np.full((1, nOutPolygonsHRU, ndom0), realMissing, dtype='f8')\n",
    "domType = np.zeros((1, nOutPolygonsHRU, ndom0), dtype='i4')\n",
    "debris_thick = np.zeros(nOutPolygonsHRU, dtype='f8')\n",
    "\n",
    "nSnow0 = np.zeros((nOutPolygonsHRU, ndom0+1), dtype='f8')\n",
    "nLake0 = np.zeros((nOutPolygonsHRU, ndom0+1), dtype='f8')\n",
    "nSoil0 = np.zeros((nOutPolygonsHRU, ndom0+1), dtype='f8')\n",
    "nGlce0 = np.zeros((nOutPolygonsHRU, ndom0+1), dtype='f8')\n",
    "\n",
    "nGlce_glac = 5 # assume same number of ice layers for every glacier if exist\n",
    "nSoil_glac = 3 # if has debris, will have this many soil layers\n",
    "ice_layDepth = np.asarray([0.15, 0.45, 2.25, 7.0, 30.0])\n",
    "ice_layDepth = ice_layDepth*4.0 # thick glacier, shouldn't need to be this thick\n",
    "nToto_glac = nGlce_glac + nSoil_glac\n",
    "iLayerHeight_glac = np.zeros((nOutPolygonsHRU,nToto_glac+1,4), dtype='f8') # 4 glacier domains\n",
    "\n",
    "nLake_wtld = 5 # assume same number of lake layers for every lake if exist\n",
    "nSoil_wtld = 3 # if has wetland, will have this many soil layers\n",
    "lakeSed_layDepth = np.asarray([0.15, 0.45, 2.25])\n",
    "nToto_wtld = nLake_wtld + nSoil_wtld\n",
    "iLayerHeight_wtld = np.zeros((nOutPolygonsHRU,nToto_wtld+1), dtype='f8') # 1 wetland domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hru data from intersections\n",
    "# domain order/type here is 1)upland, 2)glacier accumulation, 3)glacier ablation clean, 4)glacier ablation debris, 5)wetland 6)glacierets\n",
    "# RULES: Must have upland (area can be 0). If has accumulation, must have one of the ablation types, and vice versa (area can be 0).\n",
    "intersect_path = project_dir / 'shapefiles' / 'catchment_intersection' / 'with_dem_domain'\n",
    "intersect_name = 'catchment_with_dem_domain.shp'\n",
    "intersect_hruId_var = config['CATCHMENT_SHP_HRUID']\n",
    "shp_elev = gpd.read_file(intersect_path / intersect_name)\n",
    "intersect_path = project_dir / 'shapefiles' / 'catchment_intersection' / 'with_domain_type'\n",
    "intersect_name = 'catchment_with_domain_type.shp'\n",
    "shp_area = gpd.read_file(intersect_path / intersect_name)\n",
    "\n",
    "ndom = 0\n",
    "for i, hru_id in enumerate(outPolyIDs):\n",
    "    ind = 0\n",
    "    shp_mask = (shp_elev[intersect_hruId_var].astype(int) == hru_id)\n",
    "    shp_mask_count = (shp_area[intersect_hruId_var].astype(int) == hru_id)\n",
    "    if any(shp_mask):\n",
    "        for domain_type in range(1, ndom0+1):\n",
    "            column = f'elv_mean_{domain_type}'\n",
    "            # if the column exists with a valid value\n",
    "            if column in shp_elev.columns:\n",
    "                valid = True\n",
    "                if shp_elev[column][shp_mask].values[0] is None: valid = False\n",
    "                elif np.isnan(shp_elev[column][shp_mask].values[0]): valid = False\n",
    "                elif shp_elev[column][shp_mask].values[0] < 0: valid = False\n",
    "            else:\n",
    "                valid = False\n",
    "            if valid:\n",
    "                DOMelev[0,i,ind] = shp_elev[column][shp_mask].values[0]\n",
    "                DOMarea[0,i,ind] = shp_area[f'domType_{domain_type}'][shp_mask_count].values[0]\n",
    "                domType[0,i,ind] = domain_type\n",
    "                ind += 1\n",
    "            else:\n",
    "                if domain_type == 1:\n",
    "                    DOMelev[0,i,ind] = realMissing\n",
    "                    DOMarea[0,i,ind] = 0\n",
    "                    domType[0,i,ind] = domain_type\n",
    "                    ind += 1\n",
    "                elif domain_type == 2: # if has a glacier ablation zone, must have accumulation zone\n",
    "                    # NOTE: if has invalid but existing debris zone, will be replaced with clean ablation zone later as no debris thickness without valid debris zone\n",
    "                    if 'elv_mean_3' in shp_elev.columns or 'elv_mean_4' in shp_elev.columns:\n",
    "                        DOMelev[0,i,ind] = realMissing\n",
    "                        DOMarea[0,i,ind] = 0\n",
    "                        domType[0,i,ind] = domain_type\n",
    "                        ind += 1\n",
    "                elif domain_type == 3: # if has a glacier accumulation zone, must have ablation zone\n",
    "                    if 'elv_mean_2' in shp_elev.columns:\n",
    "                        if 'elv_mean_4' in shp_elev.columns: # check that valid\n",
    "                            valid_4 = True\n",
    "                            if shp_elev['elv_mean_4'][shp_mask].values[0] is None: valid_4 = False\n",
    "                            elif np.isnan(shp_elev['elv_mean_4'][shp_mask].values[0]): valid_4 = False\n",
    "                            elif shp_elev['elv_mean_4'][shp_mask].values[0] < 0: valid_4 = False\n",
    "                        else:\n",
    "                            valid_4 = False\n",
    "                        if not valid_4: # if no valid debris ablation zone, then make clean ablation zone\n",
    "                            DOMelev[0,i,ind] = realMissing\n",
    "                            DOMarea[0,i,ind] = 0\n",
    "                            domType[0,i,ind] = domain_type\n",
    "                            ind += 1\n",
    "            ndom = max(ndom,ind)\n",
    "# multiply by area and divide count by number in all domains\n",
    "for i in range(nOutPolygonsHRU):\n",
    "    if np.sum(DOMarea[0,i,:]) > 0:\n",
    "            DOMarea[0,i,:] = hru_area[i]*DOMarea[0,i,:]/np.sum(DOMarea[0,i,:])\n",
    "        \n",
    "intersect_path = project_dir / 'shapefiles' / 'catchment_intersection' / 'with_debris_thickness'\n",
    "intersect_name = 'catchment_with_debris.shp'\n",
    "shp = gpd.read_file(intersect_path / intersect_name)\n",
    "for i, hru_id in enumerate(outPolyIDs):\n",
    "    shp_mask = (shp[intersect_hruId_var].astype(int) == hru_id)\n",
    "    if any(shp_mask):\n",
    "        column = 'debri_mean'\n",
    "        # if the column exists with a valid value\n",
    "        if column in shp.columns:\n",
    "            valid = True\n",
    "            if shp[column][shp_mask].values[0] is None: valid = False\n",
    "            elif np.isnan(shp[column][shp_mask].values[0]): valid = False\n",
    "            elif shp[column][shp_mask].values[0] < 0: valid = False\n",
    "        else:\n",
    "            valid = False\n",
    "        if valid: debris_thick[i] = shp[column][shp_mask].values[0] # leave at 0 if not valid\n",
    "    if debris_thick[i]>0: # start with no snow\n",
    "        nSoil0[i,4] = nSoil_glac\n",
    "        nGlce0[i,4] = nGlce_glac\n",
    "        for layer in range(nSoil_glac+1): # debris domain is index 2 in the glacier domains\n",
    "            iLayerHeight_glac[i, layer,2] = debris_thick[i] * (layer ** 2 / nSoil_glac ** 2)\n",
    "        for layer in range(nSoil_glac+1, nGlce_glac+nSoil_glac+1):\n",
    "            iLayerHeight_glac[i, layer,2] = debris_thick[i] + ice_layDepth[layer-nSoil_glac-1]\n",
    "    # accumulation and clean and glacieret never have soil, start with no snow\n",
    "    nSoil0[i,np.asarray([2,3,6])] = 0\n",
    "    nGlce0[i,np.asarray([2,3,6])] = nGlce_glac\n",
    "    iLayerHeight_glac[i, 1:nGlce_glac+1,np.asarray([0,1,3])] = ice_layDepth\n",
    "\n",
    "# stub code block fopr wetlands\n",
    "intersect_path = project_dir / 'shapefiles' / 'catchment_intersection' / 'with_wetland'\n",
    "intersect_name = 'catchment_with_wetland.shp'\n",
    "#shp = gpd.read_file(intersect_path / intersect_name)\n",
    "#for i, hru_id in enumerate(outPolyIDs):\n",
    "#    shp_mask = (shp[intersect_hruId_var].astype(int) == hru_id)\n",
    "#    if any(shp_mask):\n",
    "#        column = 'lake_depth'\n",
    "#        # if the column exists\n",
    "#        if column in shp.columns:\n",
    "#            lake_depth[i] = shp[column][shp_mask].values[0]\n",
    "#    if lake_depth[i]>0: # start with no snow\n",
    "#        nSoil0[i,5] = nSoil_wtld\n",
    "#        nLake0[i,5] = nLake_wtld\n",
    "#        for layer in range(nLake_wtld+1):\n",
    "#            iLayerHeight_wtld[i, layer] = lake_depth[i] * (layer ** 2 / nLake_wtld ** 2)\n",
    "#        for layer in range(nLake_wtld+1, nLake_wtld+nSoil_wtld+1):\n",
    "#            iLayerHeight_wtld[i, layer] = lake_depth[i] + soil_layDepth[layer-nLake_wtld-1]\n",
    "        \n",
    "# resize arrays off ndom only\n",
    "DOMarea = DOMarea[:,:,:ndom]\n",
    "DOMelev = DOMelev[:,:,:ndom]\n",
    "domType = domType[:,:,:ndom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: glacMass4AreaChange not in standard initial conditions file\n"
     ]
    }
   ],
   "source": [
    "# default values for initial conditions\n",
    "states = {\n",
    "    'scalarCanopyIce': 0,\n",
    "    'scalarCanopyLiq': 0,\n",
    "    'scalarSnowDepth': 0,\n",
    "    'scalarSWE': 0,\n",
    "    'scalarSfcMeltPond': 0,\n",
    "    'scalarAquiferStorage': 1.0,\n",
    "    'scalarSnowAlbedo': 0,\n",
    "    'scalarCanairTemp': 283.16,\n",
    "    'scalarCanopyTemp': 283.16,\n",
    "    'mLayerTemp': 283.16,\n",
    "    'mLayerVolFracIce': 0,\n",
    "    'mLayerVolFracLiq': 0.2,\n",
    "    'mLayerMatricHead': -1.0,\n",
    "    'glacMass4AreaChange': 0, # won't be in the standard attributes file\n",
    "    'dt_init': 3600 # not a state, but include here\n",
    "}\n",
    "\n",
    "# read previously created initial conditions file, these will have every HRU upland\n",
    "nc_in = nc4.Dataset(coldstate_path, 'r')\n",
    "iLayerHeight_upld = nc_in.variables['iLayerHeight'][:,:].data.transpose()\n",
    "nSoil0[:,1] = nc_in.variables['nSoil'][:].data\n",
    "nSnow0[:,1] = nc_in.variables['nSnow'][:].data\n",
    "nToto_upld = iLayerHeight_upld.shape[1]-1\n",
    "\n",
    "# get state values, update with new values if exist\n",
    "for var_name, var_value in states.items():\n",
    "    if var_name in nc_in.variables:\n",
    "        states[var_name] = nc_in.variables[var_name][0,0].data\n",
    "    else:\n",
    "        print(f\"WARNING: {var_name} not in standard initial conditions file\")\n",
    "nc_in.close()\n",
    "\n",
    "# resize number of layer arrays\n",
    "nSnow = np.zeros((1, nOutPolygonsHRU, ndom), dtype='f8')\n",
    "nLake = np.zeros((1, nOutPolygonsHRU, ndom), dtype='f8')\n",
    "nSoil = np.zeros((1, nOutPolygonsHRU, ndom), dtype='f8')\n",
    "nGlce = np.zeros((1, nOutPolygonsHRU, ndom), dtype='f8')\n",
    "for i in range(nOutPolygonsHRU):\n",
    "    for j in range(ndom):\n",
    "        nSnow[0,i,j] = nSnow0[i,domType[0,i,j]]\n",
    "        nLake[0,i,j] = nLake0[i,domType[0,i,j]]\n",
    "        nSoil[0,i,j] = nSoil0[i,domType[0,i,j]]\n",
    "        nGlce[0,i,j] = nGlce0[i,domType[0,i,j]]\n",
    "\n",
    "# get dimensions based on maximum number of layers for layer types\n",
    "midSoil = int(nSoil.max())\n",
    "midToto = int((nSnow + nLake + nSoil + nGlce).max())\n",
    "ifcToto = midToto + 1\n",
    "scalarv = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set layer heights and depths\n",
    "iLayerHeight = np.zeros((ndom, nOutPolygonsHRU, ifcToto), dtype='f8')\n",
    "\n",
    "# fill in domain values\n",
    "for i in range(nOutPolygonsHRU):\n",
    "    for j in range(ndom):\n",
    "        if domType[0,i,j] == 1: # upland\n",
    "            iLayerHeight[j,i,:nToto_upld+1] = iLayerHeight_upld[i,:]\n",
    "        elif domType[0,i,j] == 2: # glacier accumulation\n",
    "            iLayerHeight[j,i,:nGlce_glac+1] = iLayerHeight_glac[i,:nGlce_glac+1,0]\n",
    "        elif domType[0,i,j] == 3: # glacier clean ablation\n",
    "            iLayerHeight[j,i,:nGlce_glac+1] = iLayerHeight_glac[i,:nGlce_glac+1,1]\n",
    "        elif domType[0,i,j] == 4: # glacier debris ablation\n",
    "            iLayerHeight[j,i,:nToto_glac+1] = iLayerHeight_glac[i,:,2]\n",
    "        elif domType[0,i,j] == 5: # wetland\n",
    "            iLayerHeight[j,i,:nToto_wtld+1] = iLayerHeight_wtld[i,:]\n",
    "        elif domType[0,i,j] == 6: # glacieret\n",
    "            iLayerHeight[j,i,:nGlce_glac+1] = iLayerHeight_glac[i,:nGlce_glac+1,3]\n",
    "mLayerDepth = iLayerHeight[:,:,1:] - iLayerHeight[:,:,:-1]\n",
    "\n",
    "# transpose\n",
    "iLayerHeight = iLayerHeight.transpose()\n",
    "mLayerDepth = mLayerDepth.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing output file\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding GRU_VEC data\n",
      "adding GRU_VEC data\n",
      "adding GRU_VEC data\n",
      "adding GRU_VEC data\n",
      "adding attribute data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n",
      "adding HRU_DOM data\n"
     ]
    }
   ],
   "source": [
    "# initialize netcdf file by storing dimensions and hru variable\n",
    "nc_outInit = writeNC_dims(nc_outInit_path, scalarv, midSoil, midToto, ifcToto,\n",
    "                        outPolyIDs, gruIDs, 'int', ndom, glac)\n",
    "\n",
    "# write layer variables to initial conditions file\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'iLayerHeight', 'ifcToto', 'f8', iLayerHeight)\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'mLayerDepth', 'midToto', 'f8', mLayerDepth)\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'nSnow', 'scalarv', 'f8', nSnow)\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'nLake', 'scalarv', 'f8', nLake)\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'nSoil', 'scalarv', 'f8', nSoil)\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'nGlce', 'scalarv', 'f8', nGlce)\n",
    "\n",
    "# write domain variables to initial conditions file\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'domType', 'scalarv', 'f8', domType)\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'DOMarea', 'scalarv', 'f8', DOMarea)\n",
    "writeNC_state_vars_HRU_DOM(nc_outInit, 'DOMelev', 'scalarv', 'f8', DOMelev)\n",
    "\n",
    "# write glacier variables to initial conditions file\n",
    "writeNC_state_vars_GRU_VEC(nc_outInit, 'glacAblArea', 'glac', 'f8', glacAblArea)\n",
    "writeNC_state_vars_GRU_VEC(nc_outInit, 'glacAccArea', 'glac', 'f8', glacAccArea)\n",
    "writeNC_state_vars_GRU_VEC(nc_outInit, 'lat_moraine_wid', 'glac', 'f8', lat_moraine_wid)\n",
    "writeNC_state_vars_GRU_VEC(nc_outInit, 'glacId', 'glac', 'i8', gridId)\n",
    "writeNC_state_vars_GRU(nc_outInit, 'basin__GlacierStorage', 'f8', basin__GlacierStorage)\n",
    "\n",
    "# write state variables to initial conditions file\n",
    "for var_name, var_value in states.items():\n",
    "    if var_name.startswith('mLayer'):\n",
    "        if var_name == 'mLayerMatricHead':\n",
    "            var_value_array = np.full((midSoil, nOutPolygonsHRU, ndom), var_value, dtype='f8')\n",
    "            writeNC_state_vars_HRU_DOM(nc_outInit, var_name, 'midSoil', 'f8', var_value_array) \n",
    "        else:\n",
    "            var_value_array = np.full((midToto, nOutPolygonsHRU, ndom), var_value, dtype='f8')\n",
    "            # put ice layers at -5 C, less air as go deeper with no liquid water, similar to Giese et al. 2020 (otherwise need to spin up >40 yrs)\n",
    "            if var_name == 'mLayerTemp':\n",
    "                for i in range(nOutPolygonsHRU):\n",
    "                    for j in range(ndom):\n",
    "                         if nGlce[0,i,j] > 0:\n",
    "                            start_ice = int(nSnow[0,i,j]+nLake[0,i,j]+nSoil[0,i,j])\n",
    "                            end_ice   = start_ice + int(nGlce[0,i,j])\n",
    "                            var_value_array[start_ice:end_ice,i,j] = 273.16 - 5\n",
    "            elif var_name == 'mLayerVolFracIce':\n",
    "                for i in range(nOutPolygonsHRU):\n",
    "                    for j in range(ndom):\n",
    "                        if nGlce[0,i,j] > 0:\n",
    "                            start_ice = int(nSnow[0,i,j]+nLake[0,i,j]+nSoil[0,i,j])\n",
    "                            end_ice   = start_ice + int(nGlce[0,i,j])\n",
    "                            for k in range(start_ice,end_ice):\n",
    "                                var_value_array[k, i, j] = 0.90 + (0.98 - 0.90) * (k - start_ice)**2 / (end_ice - start_ice - 1)**2\n",
    "            elif var_name == 'mLayerVolFracLiq':\n",
    "                for i in range(nOutPolygonsHRU):\n",
    "                    for j in range(ndom):\n",
    "                        if nGlce[0,i,j] > 0:\n",
    "                            start_ice = int(nSnow[0,i,j]+nLake[0,i,j]+nSoil[0,i,j])\n",
    "                            end_ice   = start_ice + int(nGlce[0,i,j])\n",
    "                            var_value_array[start_ice:end_ice,i,j] = 0.0\n",
    "            writeNC_state_vars_HRU_DOM(nc_outInit, var_name, 'midToto', 'f8', var_value_array)\n",
    "    else:\n",
    "        var_value_array = np.full((1, nOutPolygonsHRU, ndom), var_value, dtype='f8')\n",
    "        writeNC_state_vars_HRU_DOM(nc_outInit, var_name, 'scalarv', 'f8', var_value_array)\n",
    "\n",
    "# close file\n",
    "nc_outInit.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confluence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
